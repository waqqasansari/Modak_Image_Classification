{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS_xlrfvR8uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing first essential libraries\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from random import shuffle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xaHctaJSenC",
        "colab_type": "code",
        "outputId": "43c32a57-53a6-443e-ec0d-ad513e90c584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M1tabO1myY2",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pho0xiNZS09U",
        "colab_type": "code",
        "outputId": "7de0267f-e2e4-47ec-f1af-96781dd7e06a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#load our test and train data\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# this is a generator that will read pictures found in\n",
        "# subfolers of '/content/drive/My Drive/DatasetModak/train', and indefinitely generate\n",
        "# batches of augmented image data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/DatasetModak/train',  # this is the target directory\n",
        "        target_size=(150, 150),  # all images will be resized to 150x150\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
        "\n",
        "# this is a similar generator, for test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/DatasetModak/test',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 664 images belonging to 2 classes.\n",
            "Found 161 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsN7fzcdm3dJ",
        "colab_type": "text"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOCmxRZbTL8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "hist = model.compile(loss='binary_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyNRO9xLnCMC",
        "colab_type": "text"
      },
      "source": [
        "# Fit Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXyn4KbZdob9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint('model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5', verbose=1, monitor='val_acc',save_best_only=True, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_iFjBMlTVLt",
        "colab_type": "code",
        "outputId": "88e99ea4-b6c9-42c4-9748-86094710228d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=2000 // batch_size,\n",
        "        epochs=50,\n",
        "        validation_data=test_generator,\n",
        "        validation_steps=800 // batch_size,\n",
        "        callbacks=[checkpoint])\n",
        "model.save_weights('first_try.h5')  # always save your weights after training or during training"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "31/31 [==============================] - 112s 4s/step - loss: 0.6719 - acc: 0.5805 - val_loss: 0.6370 - val_acc: 0.6522\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.65217, saving model to model-001-0.580357-0.652174.h5\n",
            "Epoch 2/50\n",
            "31/31 [==============================] - 26s 833ms/step - loss: 0.6356 - acc: 0.6633 - val_loss: 0.6257 - val_acc: 0.6646\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.65217 to 0.66460, saving model to model-002-0.656798-0.664596.h5\n",
            "Epoch 3/50\n",
            "31/31 [==============================] - 25s 805ms/step - loss: 0.5903 - acc: 0.6891 - val_loss: 0.6319 - val_acc: 0.6522\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.66460\n",
            "Epoch 4/50\n",
            "31/31 [==============================] - 25s 791ms/step - loss: 0.5358 - acc: 0.7058 - val_loss: 0.6249 - val_acc: 0.6832\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.66460 to 0.68323, saving model to model-004-0.703863-0.683230.h5\n",
            "Epoch 5/50\n",
            "31/31 [==============================] - 24s 780ms/step - loss: 0.4928 - acc: 0.7490 - val_loss: 0.6443 - val_acc: 0.6708\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.68323\n",
            "Epoch 6/50\n",
            "31/31 [==============================] - 23s 745ms/step - loss: 0.4965 - acc: 0.7430 - val_loss: 0.6316 - val_acc: 0.7205\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.68323 to 0.72050, saving model to model-006-0.740880-0.720497.h5\n",
            "Epoch 7/50\n",
            "31/31 [==============================] - 26s 843ms/step - loss: 0.4327 - acc: 0.8016 - val_loss: 0.6213 - val_acc: 0.7019\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.72050\n",
            "Epoch 8/50\n",
            "31/31 [==============================] - 25s 805ms/step - loss: 0.4214 - acc: 0.8013 - val_loss: 0.6657 - val_acc: 0.6894\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.72050\n",
            "Epoch 9/50\n",
            "31/31 [==============================] - 24s 781ms/step - loss: 0.3993 - acc: 0.8116 - val_loss: 0.7250 - val_acc: 0.7453\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.72050 to 0.74534, saving model to model-009-0.811159-0.745342.h5\n",
            "Epoch 10/50\n",
            "31/31 [==============================] - 25s 797ms/step - loss: 0.3379 - acc: 0.8476 - val_loss: 0.7603 - val_acc: 0.7205\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.74534\n",
            "Epoch 11/50\n",
            "31/31 [==============================] - 25s 793ms/step - loss: 0.3345 - acc: 0.8527 - val_loss: 0.7970 - val_acc: 0.7516\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.74534 to 0.75155, saving model to model-011-0.853004-0.751553.h5\n",
            "Epoch 12/50\n",
            "31/31 [==============================] - 24s 763ms/step - loss: 0.3138 - acc: 0.8736 - val_loss: 0.6333 - val_acc: 0.7764\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.75155 to 0.77640, saving model to model-012-0.871849-0.776398.h5\n",
            "Epoch 13/50\n",
            "31/31 [==============================] - 26s 832ms/step - loss: 0.2661 - acc: 0.8829 - val_loss: 0.8277 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.77640\n",
            "Epoch 14/50\n",
            "31/31 [==============================] - 25s 802ms/step - loss: 0.2674 - acc: 0.8810 - val_loss: 0.6681 - val_acc: 0.7329\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.77640\n",
            "Epoch 15/50\n",
            "31/31 [==============================] - 23s 755ms/step - loss: 0.2463 - acc: 0.8940 - val_loss: 0.6360 - val_acc: 0.7950\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.77640 to 0.79503, saving model to model-015-0.894737-0.795031.h5\n",
            "Epoch 16/50\n",
            "31/31 [==============================] - 25s 800ms/step - loss: 0.1979 - acc: 0.9214 - val_loss: 0.7883 - val_acc: 0.8012\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.79503 to 0.80124, saving model to model-016-0.923319-0.801242.h5\n",
            "Epoch 17/50\n",
            "31/31 [==============================] - 22s 725ms/step - loss: 0.1734 - acc: 0.9291 - val_loss: 0.7158 - val_acc: 0.7950\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80124\n",
            "Epoch 18/50\n",
            "31/31 [==============================] - 26s 841ms/step - loss: 0.1750 - acc: 0.9252 - val_loss: 0.7739 - val_acc: 0.7888\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80124\n",
            "Epoch 19/50\n",
            "31/31 [==============================] - 26s 836ms/step - loss: 0.1560 - acc: 0.9402 - val_loss: 0.8654 - val_acc: 0.7391\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80124\n",
            "Epoch 20/50\n",
            "31/31 [==============================] - 25s 793ms/step - loss: 0.1411 - acc: 0.9396 - val_loss: 0.6885 - val_acc: 0.8075\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.80124 to 0.80745, saving model to model-020-0.942227-0.807453.h5\n",
            "Epoch 21/50\n",
            "31/31 [==============================] - 24s 761ms/step - loss: 0.1741 - acc: 0.9367 - val_loss: 0.8132 - val_acc: 0.7950\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80745\n",
            "Epoch 22/50\n",
            "31/31 [==============================] - 24s 790ms/step - loss: 0.1225 - acc: 0.9562 - val_loss: 1.1868 - val_acc: 0.7578\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80745\n",
            "Epoch 23/50\n",
            "31/31 [==============================] - 24s 765ms/step - loss: 0.1317 - acc: 0.9528 - val_loss: 0.9217 - val_acc: 0.7950\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80745\n",
            "Epoch 24/50\n",
            "31/31 [==============================] - 26s 840ms/step - loss: 0.0995 - acc: 0.9588 - val_loss: 0.7459 - val_acc: 0.8199\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.80745 to 0.81988, saving model to model-024-0.956140-0.819876.h5\n",
            "Epoch 25/50\n",
            "31/31 [==============================] - 25s 801ms/step - loss: 0.1056 - acc: 0.9610 - val_loss: 0.7884 - val_acc: 0.7888\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.81988\n",
            "Epoch 26/50\n",
            "31/31 [==============================] - 24s 772ms/step - loss: 0.0867 - acc: 0.9640 - val_loss: 0.8384 - val_acc: 0.8012\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.81988\n",
            "Epoch 27/50\n",
            "31/31 [==============================] - 24s 774ms/step - loss: 0.0981 - acc: 0.9563 - val_loss: 0.8953 - val_acc: 0.7950\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.81988\n",
            "Epoch 28/50\n",
            "31/31 [==============================] - 22s 720ms/step - loss: 0.1141 - acc: 0.9508 - val_loss: 0.8630 - val_acc: 0.8012\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.81988\n",
            "Epoch 29/50\n",
            "31/31 [==============================] - 26s 847ms/step - loss: 0.1123 - acc: 0.9544 - val_loss: 0.9813 - val_acc: 0.8199\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.81988\n",
            "Epoch 30/50\n",
            "31/31 [==============================] - 25s 792ms/step - loss: 0.1143 - acc: 0.9591 - val_loss: 0.8259 - val_acc: 0.8137\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.81988\n",
            "Epoch 31/50\n",
            "31/31 [==============================] - 25s 795ms/step - loss: 0.0978 - acc: 0.9603 - val_loss: 0.8087 - val_acc: 0.7826\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.81988\n",
            "Epoch 32/50\n",
            "31/31 [==============================] - 25s 805ms/step - loss: 0.0857 - acc: 0.9671 - val_loss: 0.8246 - val_acc: 0.8075\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.81988\n",
            "Epoch 33/50\n",
            "31/31 [==============================] - 24s 784ms/step - loss: 0.0683 - acc: 0.9777 - val_loss: 0.7667 - val_acc: 0.8012\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.81988\n",
            "Epoch 34/50\n",
            "31/31 [==============================] - 23s 728ms/step - loss: 0.0587 - acc: 0.9807 - val_loss: 1.0273 - val_acc: 0.7702\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.81988\n",
            "Epoch 35/50\n",
            "31/31 [==============================] - 25s 808ms/step - loss: 0.0771 - acc: 0.9697 - val_loss: 0.9387 - val_acc: 0.7888\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.81988\n",
            "Epoch 36/50\n",
            "31/31 [==============================] - 25s 816ms/step - loss: 0.0859 - acc: 0.9687 - val_loss: 1.0604 - val_acc: 0.7764\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.81988\n",
            "Epoch 37/50\n",
            "31/31 [==============================] - 24s 763ms/step - loss: 0.0702 - acc: 0.9740 - val_loss: 1.0247 - val_acc: 0.7950\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.81988\n",
            "Epoch 38/50\n",
            "31/31 [==============================] - 24s 781ms/step - loss: 0.0737 - acc: 0.9701 - val_loss: 0.8045 - val_acc: 0.8137\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.81988\n",
            "Epoch 39/50\n",
            "31/31 [==============================] - 23s 732ms/step - loss: 0.0570 - acc: 0.9780 - val_loss: 0.9751 - val_acc: 0.8012\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.81988\n",
            "Epoch 40/50\n",
            "31/31 [==============================] - 25s 820ms/step - loss: 0.0399 - acc: 0.9859 - val_loss: 1.0532 - val_acc: 0.8137\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.81988\n",
            "Epoch 41/50\n",
            "31/31 [==============================] - 25s 810ms/step - loss: 0.0548 - acc: 0.9723 - val_loss: 1.0180 - val_acc: 0.7888\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.81988\n",
            "Epoch 42/50\n",
            "31/31 [==============================] - 24s 763ms/step - loss: 0.0509 - acc: 0.9792 - val_loss: 0.9875 - val_acc: 0.7888\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.81988\n",
            "Epoch 43/50\n",
            "31/31 [==============================] - 24s 787ms/step - loss: 0.0639 - acc: 0.9798 - val_loss: 1.0579 - val_acc: 0.7329\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.81988\n",
            "Epoch 44/50\n",
            "31/31 [==============================] - 24s 777ms/step - loss: 0.0826 - acc: 0.9703 - val_loss: 0.8121 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00044: val_acc improved from 0.81988 to 0.83851, saving model to model-044-0.971030-0.838509.h5\n",
            "Epoch 45/50\n",
            "31/31 [==============================] - 22s 720ms/step - loss: 0.0562 - acc: 0.9787 - val_loss: 1.0182 - val_acc: 0.7950\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.83851\n",
            "Epoch 46/50\n",
            "31/31 [==============================] - 26s 828ms/step - loss: 0.0573 - acc: 0.9760 - val_loss: 1.1178 - val_acc: 0.7950\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.83851\n",
            "Epoch 47/50\n",
            "31/31 [==============================] - 24s 762ms/step - loss: 0.0629 - acc: 0.9744 - val_loss: 1.1680 - val_acc: 0.7578\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.83851\n",
            "Epoch 48/50\n",
            "31/31 [==============================] - 24s 779ms/step - loss: 0.0513 - acc: 0.9813 - val_loss: 0.9889 - val_acc: 0.7826\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.83851\n",
            "Epoch 49/50\n",
            "31/31 [==============================] - 24s 776ms/step - loss: 0.0373 - acc: 0.9832 - val_loss: 1.1089 - val_acc: 0.8012\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.83851\n",
            "Epoch 50/50\n",
            "31/31 [==============================] - 22s 709ms/step - loss: 0.0604 - acc: 0.9754 - val_loss: 0.9082 - val_acc: 0.8075\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.83851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aswMCEOgme33",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTXsDHYemjXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true_classes = test_generator.classes\n",
        "print(len(true_classes))\n",
        "\n",
        "\n",
        "predictions = model.predict(test_generator)\n",
        "#predicted_classes = np.argmax(predictions, axis=1)\n",
        "# print(predictions)\n",
        "type(predictions)\n",
        "type(true_classes)\n",
        "true_classes.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYSTF7BNoZs7",
        "colab_type": "code",
        "outputId": "6de2031b-ef71-475e-d13b-4720efe2682a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions[predictions < 0.5] = 0\n",
        "predictions[predictions >= 0.5] = 1\n",
        "\n",
        "# print(predictions)\n",
        "predictions.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(161, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdxzj0WxqcBT",
        "colab_type": "code",
        "outputId": "9a4cc60e-4602-4d72-9b14-1f395be3eab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions = predictions.tolist()\n",
        "\n",
        "len(predictions)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "161"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZoNYPeJrNnO",
        "colab_type": "code",
        "outputId": "844eb099-fbdc-484f-ee74-636aa8784d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "cm = confusion_matrix(true_classes, predictions)\n",
        "\n",
        "sns.heatmap(cm, annot=True)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8e9df85898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAD4CAYAAADbyJysAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nklQIE7IkFeL/A+6k7c7Dp+1fAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}